% create a basic latex article

\documentclass[12pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}

\title{Seminar - Markowitz Portfolio Optimization}
\author{PUJOL Martin \\ RAMPONT Martin \\ THOMASSIN Pablo \\ STRIEBIG Maximilien}

\date{\today}


\usepackage{amsmath}

\begin{document}

\maketitle

\section*{Theoretical Part}

\subsection*{Problem Description}

In the realm of financial portfolio management, the Markowitz portfolio optimization problem is a classical and essential topic. The primary objective is to allocate weights to different assets in a portfolio to maximize the expected return while minimizing the overall portfolio risk. Let's consider a portfolio with $n$ assets. The goal is to find the optimal set of weights for these assets.

\subsubsection*{Formalization}

An other formulation of the problem is to minimize the portfolio risk $\sigma_p$ while achieving a target expected return $\mu$:

The objective is to find the vector of weights $\mathbf{w} = [w_1, w_2, \ldots, w_n]$ that minimizes the portfolio risk $\sigma_p$ while achieving a given expected portfolio return $\mu$:

\begin{equation}
    \begin{aligned}
        \text{Minimize} \quad   & \sigma_p = \sqrt{\sum_{i=1}^{n}\sum_{j=1}^{n} w_i w_j \sigma_i \sigma_j \rho_{ij}} \quad \text{(Portfolio risk)} \\
        \text{Subject to} \quad & \mu = \sum_{i=1}^{n} r_i w_i \quad \text{(Expected portfolio return)}                                             \\
                                & \sum_{i=1}^{n} w_i = 1 \quad \text{(Sum of weights equals 1)}                                                        \\
                                & w_i \geq 0 \quad \text{(Non-negativity constraint)}
    \end{aligned}
\end{equation}


In our problem we only want to minimize the portfolio risk $\sigma_p$.



After modifying the objective function to be unconstrained, we obtain the following problem formulation:

\begin{equation}
    \begin{aligned}
        \text{Minimize} \quad   & \sigma_p^2 = \frac{1}{(\sum_{k=1}^{n} e^{x_k})^{2}} \sum_{i=1}^{n}\sum_{j=1}^{n} e^{x_i} e^{x_j}\sigma_i \sigma_j \rho_{ij} \quad \text{(Portfolio risk)} \\
    \end{aligned}
\end{equation}

With the variable change:

\begin{equation}
    w_i = \frac{e^{x_i}}{\sum_{j=1}^{n} e^{x_j}}
\end{equation}

We also calculate the derivate of the objective function:

\begin{equation}
    \begin{aligned}
        \frac{\partial}{\partial x_n} \sigma_p^2 & = \frac{-2 e^{x_n}}{(\sum_{k=1}^{N} e^{x_k})^{3}} \sum_{i=1}^{N}\sum_{j=1}^{N} e^{x_i} e^{x_j}\sigma_i \sigma_j \rho_{ij} + 2 \sigma_n e^{x_n} \sum_{j=1}^{N} e^{x_j}\sigma_j \rho_{nj} \\
    \end{aligned}
\end{equation}

\section*{Numerical Part}

\subsection*{Selected Optimization Methods}





\begin{enumerate}
    \item Method 1: [Fixed step : Gradient descent]
    \item Method 2: [Variable step : Golden section search]
\end{enumerate}

\subsection*{Algorithm Implementation}

Below are the basic functions describing the two chosen algorithms:

\subsubsection*{Method 1: [Insert Method 1 Name]}

% Insert code or pseudocode for Method 1 implementation 

The gradient step method can be formulated as follows:

\begin{equation}
    x_{k+1} = x_k - \alpha_k \nabla f(x_k)
\end{equation}
    
Where $\alpha_k$ is the step size and $\nabla f(x_k)$ is the gradient of the objective function at $x_k$.

We implemented in the following python code :



\subsubsection*{Method 2: [Insert Method 2 Name]}

[Insert code or pseudocode for Method 2 implementation]

\subsection*{Results and Analysis}

We have applied both methods to the Markowitz portfolio optimization problem and obtained the following results:

[Insert results, tables, or graphs]

\subsubsection*{Interpretation}

[Provide interpretation of the results]

\subsubsection*{Comparison}

To compare the two methods, we analyze factors such as computational time and the number of iterations:

[Insert comparison results]

\section*{Annexe : Objective function and constraints}

\subsection*{Objective function}

For solving the Markowitz portfolio optimization problem, we have chosen two numerical optimization methods:

% I want to use non-constraint optimization methods 
% Fist let's forget about the Expected return constraint

I order to simplify the problem, we will first forget about the expected return constraint. We will only focus on minimizing the portfolio risk $\sigma_p$.

\begin{equation}
    \begin{aligned}
        \text{Minimize} \quad   & \sigma_p = \sqrt{\sum_{i=1}^{n}\sum_{j=1}^{n} w_i w_j \sigma_i \sigma_j \rho_{ij}} \quad \text{(Portfolio risk)} \\
        \text{Subject to} \quad & \sum_{i=1}^{n} w_i = 1 \quad \text{(Sum of weights equals 1)}                                                        \\
                                & w_i \geq 0 \quad \text{(Non-negativity constraint)}
    \end{aligned}
\end{equation}

% To restruct the weight vector to be positive, we can use a variable change
% w_i = exp(x_i) with x_i \in R

To restruct the weight vector to be positive, we can use a variable change:
\begin{equation}
    w_i = e^{x_i} \quad \text{with} \quad x_i \in \mathbb{R}
\end{equation}

The problem becomes:

\begin{equation}
    \begin{aligned}
        \text{Minimize} \quad   & \sigma_p = \sqrt{\sum_{i=1}^{n}\sum_{j=1}^{n} e^{x_i} e^{x_j} \sigma_i \sigma_j \rho_{ij}} \quad \text{(Portfolio risk)} \\
        \text{Subject to} \quad & \sum_{i=1}^{n} e^{x_i} = 1 \quad \text{(Sum of weights equals 1)}    
    \end{aligned}
\end{equation}

We can also forget about the square root in the objective function, as it does not change the optimal solution.

\begin{equation}
    \begin{aligned}
        \text{Minimize} \quad   & \sigma_p^2 = \sum_{i=1}^{n}\sum_{j=1}^{n} e^{x_i} e^{x_j}\sigma_i \sigma_j \rho_{ij} \quad \text{(Portfolio risk)} \\
        \text{Subject to} \quad & \sum_{i=1}^{n} e^{x_i} = 1 \quad \text{(Sum of weights equals 1)}    
    \end{aligned}
\end{equation}


Finally we can use the softmax function to ensure that the sum of the weights equals 1, such as:

\begin{equation}
    w_i = \frac{e^{x_i}}{\sum_{j=1}^{n} e^{x_j}}
\end{equation}

Leading to the following problem formulation (with softmax):

\begin{equation}
    \begin{aligned}
        \text{Minimize} \quad   & \sigma_p^2 = \frac{1}{(\sum_{k=1}^{n} e^{x_k})^{2}} \sum_{i=1}^{n}\sum_{j=1}^{n} e^{x_i} e^{x_j}\sigma_i \sigma_j \rho_{ij} \quad \text{(Portfolio risk)} \\
    \end{aligned}
\end{equation}

\subsection*{Derivate of the objective function}

Now, let's delve into the derivate of the objective function:

We are going to derive it term by term using the chain rule, we first derive the term outside the sum such as :

\begin{equation}
    \frac{\partial}{\partial x_n} \frac{1}{(\sum_{k=1}^{N} e^{x_k})^{2}} = \frac{-2 e^{x_n}}{(\sum_{k=1}^{N} e^{x_k})^{3}}
\end{equation}

Where $N$ is the number of assets in the portfolio and $x_n$ is the variable we are deriving with respect to.

The second term is a bit more complicated, we will use the product rule:

\begin{equation}
    \frac{\partial}{\partial x_n} \sum_{i=1}^{N}\sum_{j=1}^{N} e^{x_i} e^{x_j}\sigma_i \sigma_j \rho_{ij} = \sum_{i=1}^{N}\sum_{j=1}^{N}( \frac{\partial}{\partial x_n} e^{x_i} ) e^{x_j}\sigma_i \sigma_j \rho_{ij} + \sum_{i=1}^{N}\sum_{j=1}^{N} e^{x_i}( \frac{\partial}{\partial x_n} e^{x_j} )\sigma_i \sigma_j \rho_{ij} 
\end{equation}

Because the two terms are similar, we will only focus on the first one:
We can see that the derivate is not null if $i \neq n$:

\begin{equation}
    \sum_{i=1}^{N}\sum_{j=1}^{N}( \frac{\partial}{\partial x_n} e^{x_i} ) e^{x_j}\sigma_i \sigma_j \rho_{ij} = \sum_{j=1}^{N} e^{x_n} e^{x_j}\sigma_n \sigma_j \rho_{nj} = \sigma_n e^{x_n} \sum_{j=1}^{N} e^{x_j}\sigma_j \rho_{nj}
\end{equation}

We can simplify the two sums by using the fact that $\rho_{ij} = \rho_{ji}$ and $\sigma_i \sigma_j = \sigma_j \sigma_i$:

\begin{equation}
    \frac{\partial}{\partial x_n} \sum_{i=1}^{N}\sum_{j=1}^{N} e^{x_i} e^{x_j}\sigma_i \sigma_j \rho_{ij} = 2 \sigma_n e^{x_n} \sum_{j=1}^{N} e^{x_j}\sigma_j \rho_{nj}
\end{equation}

Finally, we can derive the whole objective function:

\begin{equation}
    \begin{aligned}
        \frac{\partial}{\partial x_n} \sigma_p^2 & = \frac{-2 e^{x_n}}{(\sum_{k=1}^{N} e^{x_k})^{3}} \sum_{i=1}^{N}\sum_{j=1}^{N} e^{x_i} e^{x_j}\sigma_i \sigma_j \rho_{ij} + 2 \sigma_n e^{x_n} \sum_{j=1}^{N} e^{x_j}\sigma_j \rho_{nj} \\
    \end{aligned}
\end{equation}


\end{document}


